{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05b5e3df-04df-43d9-9da2-6047a9422606",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "05b5e3df-04df-43d9-9da2-6047a9422606",
    "outputId": "ee7d7f73-bc95-4795-c4bb-7c6d1670dd41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     material  Formula CrystalSystem   bulk  shear   young  poisson  Hexp\n",
      "0       mp-66  Diamond         cubic  435.3  520.5  1116.5     0.07  96.0\n",
      "1    mp-30148     BC2N  orthorhombic  361.0  422.7   912.1     0.08  76.0\n",
      "2   mp-629458     BC2N  orthorhombic  361.6  409.0   891.1     0.09  76.0\n",
      "3  mp-1018649    c-BC5      trigonal  405.8  378.2   865.6     0.14  71.0\n",
      "4     mp-1639       BN         cubic  408.0  374.5   860.2     0.15  63.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"hardness_dataset.csv\")\n",
    "\n",
    "# Check the first few rows to understand the structure\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c915f5e-3358-47e4-9785-0dbef1f92b87",
   "metadata": {
    "id": "5c915f5e-3358-47e4-9785-0dbef1f92b87"
   },
   "source": [
    "# a) Regression of experimental Hardness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed6f88bc-9635-4a16-a194-f12768690ed0",
   "metadata": {
    "id": "ed6f88bc-9635-4a16-a194-f12768690ed0"
   },
   "outputs": [],
   "source": [
    "# Split data into features and target variable\n",
    "x = df[['bulk', 'shear', 'young', 'poisson']]\n",
    "y = df['Hexp']\n",
    "\n",
    "# Split into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the feature data\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da89d5f7-ad70-4a78-9c14-47193422df96",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "da89d5f7-ad70-4a78-9c14-47193422df96",
    "outputId": "39e24826-2bd9-46e1-a329-e84378837758"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 241ms/step - loss: 442.6897 - r2_score: -1.1813 - val_loss: 473.3813 - val_r2_score: -1.1765\n",
      "Epoch 2/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 562.0645 - r2_score: -0.8851 - val_loss: 470.9218 - val_r2_score: -1.1652\n",
      "Epoch 3/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 408.9735 - r2_score: -1.1242 - val_loss: 468.4446 - val_r2_score: -1.1538\n",
      "Epoch 4/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 480.8632 - r2_score: -0.9974 - val_loss: 465.8164 - val_r2_score: -1.1417\n",
      "Epoch 5/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 520.2639 - r2_score: -0.8698 - val_loss: 463.0367 - val_r2_score: -1.1289\n",
      "Epoch 6/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 532.3087 - r2_score: -1.0197 - val_loss: 460.1010 - val_r2_score: -1.1154\n",
      "Epoch 7/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 608.2042 - r2_score: -0.6242 - val_loss: 457.1003 - val_r2_score: -1.1016\n",
      "Epoch 8/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 505.0897 - r2_score: -0.7409 - val_loss: 453.7715 - val_r2_score: -1.0863\n",
      "Epoch 9/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 427.3523 - r2_score: -0.8502 - val_loss: 450.2788 - val_r2_score: -1.0703\n",
      "Epoch 10/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 462.6448 - r2_score: -0.8726 - val_loss: 446.4752 - val_r2_score: -1.0528\n",
      "Epoch 11/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 411.6856 - r2_score: -1.0143 - val_loss: 442.6636 - val_r2_score: -1.0352\n",
      "Epoch 12/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 534.8244 - r2_score: -0.6775 - val_loss: 438.8919 - val_r2_score: -1.0179\n",
      "Epoch 13/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 364.1262 - r2_score: -0.8881 - val_loss: 435.1733 - val_r2_score: -1.0008\n",
      "Epoch 14/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 518.4777 - r2_score: -0.6731 - val_loss: 431.0934 - val_r2_score: -0.9820\n",
      "Epoch 15/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 401.6884 - r2_score: -0.6858 - val_loss: 426.8469 - val_r2_score: -0.9625\n",
      "Epoch 16/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 415.9603 - r2_score: -0.8386 - val_loss: 422.2761 - val_r2_score: -0.9415\n",
      "Epoch 17/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 468.3901 - r2_score: -0.6507 - val_loss: 416.9865 - val_r2_score: -0.9172\n",
      "Epoch 18/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 439.1202 - r2_score: -0.5760 - val_loss: 411.6143 - val_r2_score: -0.8925\n",
      "Epoch 19/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 308.6766 - r2_score: -0.8686 - val_loss: 405.5539 - val_r2_score: -0.8646\n",
      "Epoch 20/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 361.4103 - r2_score: -0.5930 - val_loss: 399.2173 - val_r2_score: -0.8355\n",
      "Epoch 21/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 309.5798 - r2_score: -0.6421 - val_loss: 392.8542 - val_r2_score: -0.8062\n",
      "Epoch 22/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 322.8962 - r2_score: -0.8429 - val_loss: 386.2397 - val_r2_score: -0.7758\n",
      "Epoch 23/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 408.6530 - r2_score: -0.6981 - val_loss: 379.5229 - val_r2_score: -0.7449\n",
      "Epoch 24/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 303.7568 - r2_score: -0.4917 - val_loss: 373.1005 - val_r2_score: -0.7154\n",
      "Epoch 25/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 377.0198 - r2_score: -0.5484 - val_loss: 366.4118 - val_r2_score: -0.6847\n",
      "Epoch 26/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 375.1850 - r2_score: -0.5302 - val_loss: 359.6225 - val_r2_score: -0.6534\n",
      "Epoch 27/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 382.0532 - r2_score: -0.4394 - val_loss: 352.5367 - val_r2_score: -0.6209\n",
      "Epoch 28/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 337.8457 - r2_score: -0.4488 - val_loss: 345.4257 - val_r2_score: -0.5882\n",
      "Epoch 29/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 246.2577 - r2_score: -0.5018 - val_loss: 338.6738 - val_r2_score: -0.5571\n",
      "Epoch 30/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 384.5486 - r2_score: -0.3632 - val_loss: 331.8060 - val_r2_score: -0.5255\n",
      "Epoch 31/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 255.8489 - r2_score: -0.4722 - val_loss: 325.1989 - val_r2_score: -0.4952\n",
      "Epoch 32/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 424.5178 - r2_score: -0.2808 - val_loss: 318.7293 - val_r2_score: -0.4654\n",
      "Epoch 33/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 285.3495 - r2_score: -0.3482 - val_loss: 312.5241 - val_r2_score: -0.4369\n",
      "Epoch 34/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 387.8704 - r2_score: -0.3073 - val_loss: 305.8445 - val_r2_score: -0.4062\n",
      "Epoch 35/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 279.9183 - r2_score: -0.4261 - val_loss: 299.4261 - val_r2_score: -0.3767\n",
      "Epoch 36/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 293.2078 - r2_score: -0.2066 - val_loss: 293.7386 - val_r2_score: -0.3505\n",
      "Epoch 37/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 361.3315 - r2_score: -0.1717 - val_loss: 288.4900 - val_r2_score: -0.3264\n",
      "Epoch 38/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 306.7265 - r2_score: -0.3486 - val_loss: 282.9242 - val_r2_score: -0.3008\n",
      "Epoch 39/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 275.1757 - r2_score: -0.2152 - val_loss: 278.0206 - val_r2_score: -0.2783\n",
      "Epoch 40/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 269.0348 - r2_score: -0.1731 - val_loss: 272.6377 - val_r2_score: -0.2535\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step\n",
      "\n",
      "Metrics for Test data before hyperparamter tuning\n",
      "Mean Absolute Error: 10.536879907805345\n",
      "Mean Squared Error: 272.63771705544195\n",
      "Root Mean Squared Error: 16.511744821654734\n",
      "R2 Score: -0.2535090750568545\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.metrics import R2Score\n",
    "\n",
    "#setting up the ANN\n",
    "# first layer is number of features\n",
    "# last layer is output layer. Nodes=1 for binary classification\n",
    "model = Sequential()\n",
    "model.add(Dense(units=x_train.shape[1],activation='sigmoid'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(units=6,activation='relu'))\n",
    "model.add(Dense(units=4,activation='relu'))\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "model.compile(loss='mse',optimizer='adam',metrics=[R2Score])\n",
    "\n",
    "model.fit(x=x_train, y=y_train,epochs=40,validation_data=(x_test, y_test), batch_size = 10, verbose=1 )\n",
    "\n",
    "# get prediction on test data\n",
    "predictions_train=model.predict(x_train)\n",
    "predictions_test=model.predict(x_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "# Metrics for test data\n",
    "print(\"\\nMetrics for Test data before hyperparamter tuning\")\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, predictions_test))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, predictions_test))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error (y_test, predictions_test)))\n",
    "print('R2 Score:', metrics.r2_score(y_test, predictions_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5a5e112-eff0-4c28-a772-8b95f4fe1a0e",
   "metadata": {
    "id": "f5a5e112-eff0-4c28-a772-8b95f4fe1a0e"
   },
   "outputs": [],
   "source": [
    "#hyperparameter tuning\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "\n",
    "def build_model(hp):\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # Input + first hidden layer\n",
    "    model.add(Dense(\n",
    "        units=hp.Int('units_input', min_value=4, max_value=64, step=4),\n",
    "        activation='relu',\n",
    "        input_shape=(x_train.shape[1],)\n",
    "    ))\n",
    "\n",
    "    # Tune number of additional hidden layers (1 to 3)\n",
    "    for i in range(hp.Int('num_layers', 1, 3)):\n",
    "        model.add(Dense(\n",
    "            units=hp.Int(f'units_{i}', min_value=4, max_value=64, step=4),\n",
    "            activation='relu'\n",
    "        ))\n",
    "        #uncomment if you want a droput layer\n",
    "        # if hp.Boolean(f'dropout_{i}'):\n",
    "        #     model.add(Dropout(rate=hp.Float(f'dropout_rate_{i}', 0.1, 0.5, step=0.1)))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    # Optimizer tuning\n",
    "    optimizer_choice = hp.Choice('optimizer', ['adam', 'rmsprop'])\n",
    "    if optimizer_choice == 'adam':\n",
    "        optimizer = Adam(learning_rate=hp.Float('adam_lr', 1e-4, 1e-2, sampling='log'))\n",
    "    else:\n",
    "        optimizer = RMSprop(learning_rate=hp.Float('rms_lr', 1e-4, 1e-2, sampling='log'))\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=[\"mae\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7c5474e-3e42-4063-ad26-0da58e13319a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f7c5474e-3e42-4063-ad26-0da58e13319a",
    "outputId": "608ce5a1-7c32-4f54-a622-c6d778b6a173"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m122.9/129.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.4/129.4 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "#!pip install -q -U keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3518551-6588-4b2c-99cd-ec82017b440b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e3518551-6588-4b2c-99cd-ec82017b440b",
    "outputId": "f639a0ae-273c-471e-8c01-67178b0d7cf0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 00m 05s]\n",
      "val_mae: 3.2109785079956055\n",
      "\n",
      "Best val_mae So Far: 3.1155261993408203\n",
      "Total elapsed time: 00h 01m 08s\n"
     ]
    }
   ],
   "source": [
    "#from kerastuner.tuners import RandomSearch\n",
    "import keras_tuner as kt\n",
    "\n",
    "tuner = kt.RandomSearch(build_model,\n",
    "                        objective='val_mae',       # minimize validation MAE\n",
    "                        max_trials=10,           # number of random configurations to test\n",
    "                        directory='tuner_dir',\n",
    "                        project_name='ann_random_search'\n",
    ")\n",
    "# You can print a summary of the search space\n",
    "#tuner.search_space_summary()\n",
    "\n",
    "tuner.search(x_train, y_train, epochs=10, validation_data=(x_test, y_test), batch_size=5, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38bbc781-2ec6-4938-a8c9-a2a20d5ad9ab",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "38bbc781-2ec6-4938-a8c9-a2a20d5ad9ab",
    "outputId": "f0b2ca00-6a01-4f58-b6ce-4efba4973cfd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters found:\n",
      "units_input: 20\n",
      "num_layers: 2\n",
      "units_0: 24\n",
      "optimizer: adam\n",
      "adam_lr: 0.0017036374364839458\n",
      "rms_lr: 0.0029517692699950553\n",
      "units_1: 56\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/usr/local/lib/python3.12/dist-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 18 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 165ms/step - loss: 20.1830 - mae: 3.1924 - val_loss: 43.6463 - val_mae: 4.5406\n",
      "Epoch 2/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 29.1951 - mae: 3.6483 - val_loss: 21.7244 - val_mae: 3.2951\n",
      "Epoch 3/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 16.8633 - mae: 2.9234 - val_loss: 19.7247 - val_mae: 3.3377\n",
      "Epoch 4/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 19.1003 - mae: 3.0764 - val_loss: 29.0949 - val_mae: 3.5506\n",
      "Epoch 5/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 20.1479 - mae: 3.2501 - val_loss: 20.7246 - val_mae: 3.3198\n",
      "Epoch 6/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 11.4589 - mae: 2.4891 - val_loss: 24.5579 - val_mae: 3.5537\n",
      "Epoch 7/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 20.4691 - mae: 3.2524 - val_loss: 17.8250 - val_mae: 3.1184\n",
      "Epoch 8/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 23.8546 - mae: 3.3872 - val_loss: 18.2968 - val_mae: 3.1855\n",
      "Epoch 9/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 15.2517 - mae: 2.8548 - val_loss: 17.8338 - val_mae: 3.0903\n",
      "Epoch 10/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 15.7311 - mae: 2.8341 - val_loss: 18.0907 - val_mae: 3.1453\n",
      "Epoch 11/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 14.6128 - mae: 2.9034 - val_loss: 17.9275 - val_mae: 3.0746\n",
      "Epoch 12/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 17.7831 - mae: 3.0528 - val_loss: 17.5300 - val_mae: 3.1458\n",
      "Epoch 13/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 12.3093 - mae: 2.5402 - val_loss: 18.7667 - val_mae: 3.2163\n",
      "Epoch 14/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 11.8791 - mae: 2.5197 - val_loss: 17.9011 - val_mae: 3.1811\n",
      "Epoch 15/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 10.2774 - mae: 2.3592 - val_loss: 27.4097 - val_mae: 3.6848\n",
      "Epoch 16/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 23.7802 - mae: 3.2429 - val_loss: 22.9901 - val_mae: 3.3757\n",
      "Epoch 17/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 11.3457 - mae: 2.3736 - val_loss: 22.0999 - val_mae: 3.4188\n",
      "Epoch 18/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 17.3997 - mae: 2.9903 - val_loss: 20.8103 - val_mae: 3.2469\n",
      "Epoch 19/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 13.1055 - mae: 2.6293 - val_loss: 18.1001 - val_mae: 3.1852\n",
      "Epoch 20/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 10.7250 - mae: 2.3545 - val_loss: 19.4050 - val_mae: 3.1977\n",
      "Epoch 21/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 13.1878 - mae: 2.5372 - val_loss: 25.5812 - val_mae: 3.4654\n",
      "Epoch 22/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 13.1000 - mae: 2.6763 - val_loss: 24.4240 - val_mae: 3.3570\n",
      "Epoch 23/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 16.5371 - mae: 2.5513 - val_loss: 23.0181 - val_mae: 3.4328\n",
      "Epoch 24/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 15.3050 - mae: 2.8459 - val_loss: 18.9198 - val_mae: 3.2338\n",
      "Epoch 25/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 15.2677 - mae: 2.8217 - val_loss: 18.5951 - val_mae: 3.1753\n",
      "Epoch 26/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 11.2315 - mae: 2.4338 - val_loss: 17.1164 - val_mae: 3.0900\n",
      "Epoch 27/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 13.2694 - mae: 2.7165 - val_loss: 23.2845 - val_mae: 3.3856\n",
      "Epoch 28/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 25.0478 - mae: 3.5929 - val_loss: 39.1522 - val_mae: 4.2508\n",
      "Epoch 29/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 27.2042 - mae: 3.5752 - val_loss: 37.4095 - val_mae: 4.3206\n",
      "Epoch 30/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 24.7926 - mae: 3.2580 - val_loss: 20.0595 - val_mae: 3.1327\n",
      "Epoch 31/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 11.4026 - mae: 2.4160 - val_loss: 18.7485 - val_mae: 3.2461\n",
      "Epoch 32/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 12.4405 - mae: 2.5834 - val_loss: 25.5157 - val_mae: 3.5012\n",
      "Epoch 33/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 14.1476 - mae: 2.5973 - val_loss: 25.1308 - val_mae: 3.2267\n",
      "Epoch 34/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 21.2080 - mae: 3.3160 - val_loss: 19.3653 - val_mae: 3.1571\n",
      "Epoch 35/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 17.3925 - mae: 3.0015 - val_loss: 20.2842 - val_mae: 3.2490\n",
      "Epoch 36/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 13.1714 - mae: 2.6895 - val_loss: 17.8436 - val_mae: 3.0957\n",
      "Epoch 37/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 11.0492 - mae: 2.3673 - val_loss: 17.7950 - val_mae: 3.0998\n",
      "Epoch 38/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 10.8122 - mae: 2.4910 - val_loss: 17.4320 - val_mae: 3.0758\n",
      "Epoch 39/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 18.0740 - mae: 2.9988 - val_loss: 22.9404 - val_mae: 3.3509\n",
      "Epoch 40/40\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 17.4629 - mae: 3.1935 - val_loss: 21.9317 - val_mae: 3.1858\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285ms/step\n",
      "\n",
      "Metrics for Test data after hyper paramter tuning\n",
      "Mean Absolute Error: 3.1857957001390123\n",
      "Mean Squared Error: 21.931714191234672\n",
      "Root Mean Squared Error: 4.683130810818193\n",
      "R2 Score: 0.8991643450246638\n"
     ]
    }
   ],
   "source": [
    "best_hp = tuner.get_best_hyperparameters(1)[0]\n",
    "\n",
    "print(\"Best hyperparameters found:\")\n",
    "for k, v in best_hp.values.items():\n",
    "    print(f\"{k}: {v}\")\n",
    "\n",
    "#extract best model\n",
    "best_model = tuner.get_best_models(1)[0]\n",
    "\n",
    "#refit\n",
    "best_model.fit(x=x_train, y=y_train,epochs=40,validation_data=(x_test, y_test), batch_size = 10, verbose=1 )\n",
    "\n",
    "predictions_train=best_model.predict(x_train)\n",
    "predictions_test=best_model.predict(x_test)\n",
    "\n",
    "# Metrics for test data\n",
    "print(\"\\nMetrics for Test data after hyper paramter tuning\")\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, predictions_test))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, predictions_test))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error (y_test, predictions_test)))\n",
    "print('R2 Score:', metrics.r2_score(y_test, predictions_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-2qfx2wT1AdG",
   "metadata": {
    "id": "-2qfx2wT1AdG"
   },
   "source": [
    "You need to summerize the results here and highlight the best model and metrics."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
